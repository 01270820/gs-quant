{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e13c8d65",
   "metadata": {},
   "source": [
    "# Quant Backtesting Workflow in Marquee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d01541",
   "metadata": {},
   "source": [
    "## Step 1: Authenticate and Initialize your Session \n",
    "\n",
    "First you will import the necessary modules and add your client id and client secret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import time\n",
    "from math import copysign\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from gs_quant.datetime.relative_date import RelativeDate\n",
    "from gs_quant.markets.position_set import Position, PositionSet, PositionTag\n",
    "from gs_quant.markets.portfolio import Portfolio\n",
    "from gs_quant.markets.portfolio_manager import PortfolioManager\n",
    "from gs_quant.markets.securities import Asset, AssetIdentifier\n",
    "from gs_quant.markets.report import FactorRiskReport, ReturnFormat\n",
    "from gs_quant.models.risk_model import FactorRiskModel\n",
    "from gs_quant.session import GsSession\n",
    "from gs_quant.target.common import PositionSetWeightingStrategy\n",
    "\n",
    "from gs_quant.target.hedge import CorporateActionsTypes\n",
    "from gs_quant.markets.optimizer import (\n",
    "    OptimizerStrategy,\n",
    "    OptimizerUniverse,\n",
    "    AssetConstraint,\n",
    "    FactorConstraint,\n",
    "    SectorConstraint,\n",
    "    OptimizerSettings,\n",
    "    OptimizerConstraints,\n",
    "    OptimizerObjective,\n",
    "    OptimizerType,\n",
    ")\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "client = None\n",
    "secret = None\n",
    "\n",
    "## External users must fill in their client ID and secret below and comment out the line below\n",
    "# client = 'ENTER CLIENT ID'\n",
    "# secret = 'ENTER CLIENT SECRET'\n",
    "\n",
    "GsSession.use(client_id=client, client_secret=secret)\n",
    "\n",
    "print('GS Session initialized.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dbcc5251b6725f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Step 2: Create a Portfolio\n",
    "\n",
    "#### Quick Tips: \n",
    "- If you already have a portfolio and just want to update your positions refer to the 03_Update_Historical_Portfolio tutorial in *_gs_quant\\documentation\\10_one_delta\\Portfolios_*.\n",
    "- If you already have a finalized portfolio, you can skip to the end of Step 2 and use the `PortfolioManager({ YOUR PORTFOLIO ID })`class to pull your portfolio.\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "Let's setup our starting point. We'll create a small portfolio with 3 stocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60039d9549afdc5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "start_date = dt.date(2024, 1, 2)\n",
    "reference_notional = 100_000_000\n",
    "hedge_notional_pct = 0.4\n",
    "universe = ['SPX']\n",
    "rebalance_freq = '3m'\n",
    "risk_model_id = 'AXIOMA_AXUS4S'\n",
    "holdings = [\n",
    "    {'identifier': 'AAPL UW', 'weight': 0.4, 'source': 'Portfolio'},\n",
    "    {'identifier': 'MSFT UW', 'weight': 0.25, 'source': 'Portfolio'},\n",
    "    {'identifier': 'META UW', 'weight': 0.25, 'source': 'Portfolio'},\n",
    "]\n",
    "apply_factor_constraints_on_total = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28dfc1fb4300a20f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Quick Tip: \n",
    "If you do not have historical identifiers of your holdings, you can use SecurityMaster to resolve today's identifiers to a past point in time. In this example, META is an identifier as of today, not as of 2020.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8122d4ab8610db6a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gs_quant.api.gs.secmaster import GsSecurityMasterApi\n",
    "\n",
    "historical_identifiers = {}\n",
    "\n",
    "\n",
    "def get_historical_id(identifier, date, listed=True, id_type='bbid'):\n",
    "    data = GsSecurityMasterApi.get_many_securities(**{\"identifier\": [identifier], \"isPrimary\": True})\n",
    "    if not data or 'results' not in data or not data['results']:\n",
    "        raise ValueError(f\"No security found for identifier {identifier}\")\n",
    "    secm_id = data['results'][0]['id']\n",
    "    historical_data = GsSecurityMasterApi.get_identifiers(secmaster_id=secm_id)\n",
    "    for record in historical_data:\n",
    "        start_date = dt.datetime.strptime(record['startDate'], '%Y-%m-%d').date()\n",
    "        end_date = (\n",
    "            dt.datetime.strptime(record['endDate'], '%Y-%m-%d').date()\n",
    "            if record['endDate'] != '9999-99-99'\n",
    "            else dt.date.today()\n",
    "        )\n",
    "        if start_date <= date <= end_date:\n",
    "            if listed and record['type'] == id_type:\n",
    "                return record['value']\n",
    "    return identifier\n",
    "\n",
    "\n",
    "holdings = [\n",
    "    {'identifier': 'META UW'},\n",
    "]\n",
    "start_date = dt.date(2020, 1, 1)\n",
    "\n",
    "for holding in holdings:\n",
    "    try:\n",
    "        historical_identifiers[holding['identifier']] = get_historical_id(holding['identifier'], start_date)\n",
    "    except ValueError as e:\n",
    "        print(e)\n",
    "\n",
    "historical_identifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348122bdff707adb",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You can then use these point in time identifiers to update your holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4495f9531c9378",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to replace incorrect identifiers with correct ones\n",
    "def update_identifiers(holdings, historical_identifiers):\n",
    "    for holding in holdings:\n",
    "        incorrect_id = holding['identifier']\n",
    "        if incorrect_id in historical_identifiers:\n",
    "            holding['identifier'] = historical_identifiers[incorrect_id]\n",
    "    return holdings\n",
    "\n",
    "\n",
    "# Update the portfolio positions\n",
    "updated_holdings = update_identifiers(holdings, historical_identifiers)\n",
    "\n",
    "# Print the updated portfolio positions\n",
    "updated_holdings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c330e417e4641a7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Once the holdings are finalized, we convert them to a PositionSet object, and resolve them to Marquee Identifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad18bac693f0105",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "position_set = PositionSet.from_dicts(holdings, date=start_date, add_tags=True, reference_notional=reference_notional)\n",
    "position_set.resolve()\n",
    "\n",
    "position_set.to_frame(add_tags=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea59c09",
   "metadata": {},
   "source": [
    "We also price our positions to filter out any assets that might be missing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b38fc04b8d5671d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_pset = position_set.clone()\n",
    "combined_pset.price(\n",
    "    use_unadjusted_close_price=True, weighting_strategy=PositionSetWeightingStrategy.Weight, fallbackDate='5d'\n",
    ")\n",
    "combined_pset.positions.append(\n",
    "    Position(\n",
    "        identifier='USD',\n",
    "        quantity=hedge_notional_pct * reference_notional * -1,\n",
    "        tags=[PositionTag(name='source', value='Optimization')],\n",
    "    )\n",
    ")\n",
    "combined_pset.resolve()\n",
    "combined_pset.price(use_unadjusted_close_price=True, fallbackDate='5d', handle_long_short=True)\n",
    "\n",
    "combined_pset.to_frame(add_tags=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e99bc9",
   "metadata": {},
   "source": [
    "You can now create your portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98c7d30f6f886a7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "portfolio = Portfolio(name='My New Strategy')\n",
    "portfolio.save()\n",
    "print('Created portfolio with id: {0}'.format(portfolio.id))\n",
    "port_id = portfolio.id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aeea084",
   "metadata": {},
   "source": [
    "Once the portfolio has been created, upload your position set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9362d1c6221d86fd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "port_manager = PortfolioManager(port_id)\n",
    "# share the portfolio with your account, as your app is different from yourself\n",
    "port_manager.share(emails=['user.1@yourcompany.com'], admin=True)\n",
    "port_manager.share(emails=['user.2@yourcompany.com'], admin=False)\n",
    "port_manager.update_positions([combined_pset])\n",
    "port_manager.set_tag_name_hierarchy(['source'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21147fd9",
   "metadata": {},
   "source": [
    "## Step 3: Run Factor Risk Reports\n",
    "\n",
    "We can now schedule Factor Risk Reports for our portfolio and extract factor exposure data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6f5768cc18b35b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "risk_report = FactorRiskReport(risk_model_id=risk_model_id)\n",
    "risk_report.set_position_source(port_id)\n",
    "risk_report.save()\n",
    "\n",
    "port_manager.update_portfolio_tree()\n",
    "port_manager.schedule_reports(start_date=position_set.date, end_date=RelativeDate(\"5b\", position_set.date).apply_rule())\n",
    "\n",
    "print('Waiting for risk calculations to complete...')\n",
    "risk_report = port_manager.get_factor_risk_report(risk_model_id=risk_model_id, tags={'source': 'Portfolio'})\n",
    "risk_report.get_most_recent_job().wait_for_completion()\n",
    "\n",
    "factor_exposure_data = risk_report.get_factor_exposure(start_date=position_set.date, end_date=position_set.date)\n",
    "factor_exposure_map = factor_exposure_data.to_dict(orient='records')[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdddaef6",
   "metadata": {},
   "source": [
    "## Step 4: Hedge Your Position Set\n",
    "Now that you have a position set, you can get a hedge according to your liking."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24edd1b8",
   "metadata": {},
   "source": [
    "`prepare_factor_constraints` below will pull constraints defined at a portfolio level to apply on the hedge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9286ce2c6ece38cd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prepare_factor_constraints(factor_constraints, port_factor_exposure_map):\n",
    "    \"\"\"Given factor constraints defined on the total portfolio and factor exposures of the core portfolio,\n",
    "    return constraints to be applied on the hedge\"\"\"\n",
    "    new_constraints = []\n",
    "    for fc in factor_constraints:\n",
    "        old = fc.max_exposure\n",
    "        new = port_factor_exposure_map.get(fc.factor.name, 0) - fc.max_exposure\n",
    "        print('Changing factor constraint for ', fc.factor.name, 'from ', old, 'to ', new)\n",
    "        new_constraints.append(\n",
    "            FactorConstraint(fc.factor, port_factor_exposure_map.get(fc.factor.name, 0) - fc.max_exposure)\n",
    "        )\n",
    "    return new_constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6800b724c0bfa2ff",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We have put in some sample settings below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ffee757033b0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hedge_universe = OptimizerUniverse(\n",
    "    assets=[Asset.get(a, AssetIdentifier.BLOOMBERG_ID) for a in universe],\n",
    "    explode_composites=True,\n",
    "    exclude_corporate_actions_types=[CorporateActionsTypes.Mergers],\n",
    ")\n",
    "\n",
    "risk_model = FactorRiskModel.get(risk_model_id)\n",
    "\n",
    "asset_constraints = [\n",
    "    AssetConstraint(Asset.get('MSFT UW', AssetIdentifier.BLOOMBERG_ID), 0, 5),\n",
    "    AssetConstraint(Asset.get('AAPL UW', AssetIdentifier.BLOOMBERG_ID), 0, 5),\n",
    "]\n",
    "\n",
    "# here, we have specified the constraints on factor exposure of the Total Optimized portfolio\n",
    "factor_constraints = [\n",
    "    FactorConstraint(risk_model.get_factor('Size'), 0),\n",
    "    FactorConstraint(risk_model.get_factor('Market Sensitivity'), 0),\n",
    "]\n",
    "\n",
    "if apply_factor_constraints_on_total:\n",
    "    hedge_factor_constraints = prepare_factor_constraints(factor_constraints, factor_exposure_map)\n",
    "else:\n",
    "    hedge_factor_constraints = factor_constraints\n",
    "\n",
    "sector_constraints = [SectorConstraint('Energy', 0, 30), SectorConstraint('Health Care', 0, 30)]\n",
    "settings = OptimizerSettings(\n",
    "    notional=hedge_notional_pct * position_set.reference_notional,  # 40% of your original portfolio\n",
    "    allow_long_short=False,\n",
    ")\n",
    "constraints = OptimizerConstraints(\n",
    "    asset_constraints=asset_constraints,\n",
    "    factor_constraints=hedge_factor_constraints,\n",
    "    sector_constraints=sector_constraints,\n",
    ")\n",
    "\n",
    "strategy = OptimizerStrategy(\n",
    "    initial_position_set=position_set,\n",
    "    constraints=constraints,\n",
    "    settings=settings,\n",
    "    universe=hedge_universe,\n",
    "    risk_model=risk_model,\n",
    "    objective=OptimizerObjective.MINIMIZE_FACTOR_RISK,\n",
    ")\n",
    "\n",
    "strategy.run(optimizer_type=OptimizerType.AXIOMA_PORTFOLIO_OPTIMIZER)\n",
    "\n",
    "optimization = strategy.get_optimization(\n",
    "    by_weight=True\n",
    ")  # Returns just the optimization results as a PositionSet object\n",
    "optimization.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b77816be333b3a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "While the Optimizer uses adjusted prices, portfolio services use unadjusted prices to offer users more fine-grained control on historical positions. \n",
    "We need to convert the output from our hedge to unadjusted prices to be able to use it in portfolio services."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb9251c171a8a",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "position_set.price(\n",
    "    use_unadjusted_close_price=True, weighting_strategy=PositionSetWeightingStrategy.Weight, fallbackDate='5d'\n",
    ")\n",
    "\n",
    "optimization.price(\n",
    "    use_unadjusted_close_price=True, weighting_strategy=PositionSetWeightingStrategy.Weight, fallbackDate='5d'\n",
    ")\n",
    "\n",
    "for p in optimization.positions:\n",
    "    p.quantity *= -1\n",
    "    p.add_tag('source', 'Optimization')\n",
    "\n",
    "combined_pset = PositionSet(\n",
    "    date=position_set.date,\n",
    "    # take only quantity of the newly priced positions\n",
    "    positions=[\n",
    "        Position(identifier=p.identifier, asset_id=p.asset_id, quantity=p.quantity, tags=p.tags)\n",
    "        for p in position_set.positions + optimization.positions\n",
    "    ],\n",
    ")\n",
    "combined_pset.to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60cf9f24",
   "metadata": {},
   "source": [
    "You can now upload the positions and reschedule any report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff94b8b386e7d99",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "port_manager.update_positions([combined_pset])\n",
    "port_manager.schedule_reports(\n",
    "    start_date=combined_pset.date, end_date=RelativeDate(rebalance_freq, combined_pset.date).apply_rule()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d17b661",
   "metadata": {},
   "source": [
    "# Step 5: Continuous Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81de648080f25477",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "With our initial setup done and settings configured, we are now ready to launch a flow that will continuously optimize our portfolio at our desired frequency.\n",
    "\n",
    "We'll take thw positions from the previous rebalance, utilize performance analytics to get the latest positions, and then optimize the portfolio again. \n",
    "\n",
    "We'll then update the portfolio with the new positions and schedule reports for the next rebalance date.\n",
    "\n",
    "This operation of moving your portfolio forward using performance analytics relies solely on availability of the underlying assets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a57977f27fa4717",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "port_manager = PortfolioManager(port_id)\n",
    "start = position_set.date\n",
    "max_end = RelativeDate(\"-1b\", dt.date.today()).apply_rule(exchanges=['NYSE'])\n",
    "start_time = time.time()\n",
    "rebal = RelativeDate(rebalance_freq, start).apply_rule(exchanges=['NYSE'])\n",
    "\n",
    "while rebal < max_end:\n",
    "    print(f'Moving to rebalance date {rebal}')\n",
    "    port_perf_report = port_manager.get_performance_report({'source': 'Portfolio'})\n",
    "    perf_report_job = port_perf_report.get_most_recent_job()\n",
    "    print(\n",
    "        f'Waiting for performance calculations till date {perf_report_job.end_date} to complete (job id {perf_report_job.job_id})'\n",
    "    )\n",
    "    perf_report_job.wait_for_completion()\n",
    "\n",
    "    latest_port_pos = port_perf_report.get_portfolio_constituents(\n",
    "        start_date=rebal,\n",
    "        end_date=rebal,\n",
    "        fields=['quantity', 'grossWeight'],\n",
    "        prefer_rebalance_positions=True,\n",
    "        return_format=ReturnFormat.JSON,\n",
    "    )\n",
    "    latest_port_exp = port_perf_report.get_gross_exposure(start_date=rebal, end_date=rebal)['grossExposure'][0]\n",
    "    latest_position_set = PositionSet(\n",
    "        date=rebal,\n",
    "        reference_notional=latest_port_exp,\n",
    "        positions=[\n",
    "            Position(\n",
    "                asset_id=p['assetId'],\n",
    "                identifier=p['assetId'],\n",
    "                # We recommend using gross weight to find your reference weight, like below\n",
    "                weight=copysign(p.get('grossWeight', 0), p.get('quantity', 0)),\n",
    "                tags=[{'source': 'Portfolio'}],\n",
    "            )\n",
    "            for p in latest_port_pos\n",
    "        ],\n",
    "    )\n",
    "    print('Latest Portfolio Position set:')\n",
    "    print(latest_position_set.to_frame(add_tags=True))\n",
    "    settings = OptimizerSettings(\n",
    "        notional=hedge_notional_pct * latest_position_set.reference_notional,  # 30% of your original portfolio\n",
    "        allow_long_short=False,\n",
    "    )\n",
    "\n",
    "    if factor_constraints and apply_factor_constraints_on_total:\n",
    "        port_risk_report = port_manager.get_factor_risk_report(\n",
    "            risk_model_id=risk_model_id, tags={'source': 'Portfolio'}\n",
    "        )\n",
    "        risk_report_job = port_risk_report.get_most_recent_job()\n",
    "        print(\n",
    "            f'Waiting for risk calculations till date {risk_report_job.end_date} to complete (job id {risk_report_job.job_id})'\n",
    "        )\n",
    "        risk_report_job.wait_for_completion()\n",
    "\n",
    "        factor_exposure_data = risk_report.get_factor_exposure(\n",
    "            start_date=latest_position_set.date, end_date=latest_position_set.date\n",
    "        )\n",
    "        factor_exposure_map = factor_exposure_data.to_dict(orient='records')[0]\n",
    "        hedge_factor_constraints = prepare_factor_constraints(factor_constraints, factor_exposure_map)\n",
    "    else:\n",
    "        hedge_factor_constraints = factor_constraints\n",
    "\n",
    "    constraints = OptimizerConstraints(\n",
    "        asset_constraints=asset_constraints,\n",
    "        factor_constraints=hedge_factor_constraints,\n",
    "        sector_constraints=sector_constraints,\n",
    "    )\n",
    "    strategy = OptimizerStrategy(\n",
    "        initial_position_set=latest_position_set,\n",
    "        constraints=constraints,\n",
    "        settings=settings,\n",
    "        universe=hedge_universe,\n",
    "        risk_model=risk_model,\n",
    "        objective=OptimizerObjective.MINIMIZE_FACTOR_RISK,\n",
    "    )\n",
    "    print('Optimizing...')\n",
    "    strategy.run(optimizer_type=OptimizerType.AXIOMA_PORTFOLIO_OPTIMIZER)\n",
    "    print('Optimization complete')\n",
    "    print('Optimized Position Set quantities:')\n",
    "    print(strategy.get_optimized_position_set().to_frame())\n",
    "    optimization = strategy.get_optimization(by_weight=True)\n",
    "    print('Hedge position set:')\n",
    "    print(optimization.to_frame(add_tags=True))\n",
    "    optimization.price(\n",
    "        use_unadjusted_close_price=True, weighting_strategy=PositionSetWeightingStrategy.Weight, fallbackDate='5d'\n",
    "    )\n",
    "    for p in optimization.positions:\n",
    "        p.add_tag('source', 'Optimization')\n",
    "    latest_position_set.price(\n",
    "        use_unadjusted_close_price=True, weighting_strategy=PositionSetWeightingStrategy.Weight, fallbackDate='5d'\n",
    "    )\n",
    "    combined_pset = PositionSet(\n",
    "        date=optimization.date,\n",
    "        positions=[\n",
    "            Position(identifier=p.identifier, asset_id=p.asset_id, quantity=p.quantity, tags=p.tags)\n",
    "            for p in latest_position_set.positions + optimization.positions\n",
    "        ],\n",
    "    )\n",
    "    print('Combined position set:')\n",
    "    print(combined_pset.to_frame(add_tags=True))\n",
    "    port_manager.update_positions([combined_pset])\n",
    "    start = rebal\n",
    "    rebal = min(max_end, RelativeDate(rebalance_freq, start).apply_rule())\n",
    "    print(f'Scheduling reports to calculate performance till {rebal}...')\n",
    "    port_manager.schedule_reports(start_date=start, end_date=rebal)\n",
    "    time.sleep(2)\n",
    "\n",
    "print(f'Done! Processing completed in {time.time() - start_time} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23208a6f7f529d31",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "And that's it! You have successfully completed a basic run of our Quant Backtesting Workflow. \n",
    "\n",
    "For questions, please reach out to [Marquee Sales](mailto:gs-marquee-sales@gs.com)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
